import os
import tempfile
import subprocess
import yaml
from pathlib import Path
from typing import Dict, Any, List
from .base_agent import BaseAgent
import logging

logger = logging.getLogger(__name__)

class AgniAgent(BaseAgent):
    """Build & Dockerization Agent - Agni"""
    
    def __init__(self, llm_client, config: Dict[str, Any]):
        super().__init__("Agni", llm_client, config)
    
    def _run_docker_cmd(self, args: List[str], cwd: Path | None = None, timeout: int = 600) -> subprocess.CompletedProcess:
        """Run a docker CLI command and return the completed process."""
        cmd = ["docker", *args]
        result = subprocess.run(
            cmd,
            cwd=str(cwd) if cwd else None,
            capture_output=True,
            text=True,
            timeout=timeout,
            env=os.environ.copy(),
        )
        if result.returncode != 0:
            raise Exception(f"docker {' '.join(args)} failed: {result.stderr.strip() or result.stdout.strip()}")
        return result
    
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute build and containerization"""
        self.start_execution()
        
        try:
            project_path = Path(input_data["project_path"])
            build_plan = input_data["build_plan"]
            tech_stack = input_data["tech_stack"]
            
            # Generate Dockerfile
            dockerfile_content = self._generate_dockerfile(build_plan, tech_stack)
            dockerfile_path = project_path / "Dockerfile"
            
            with open(dockerfile_path, 'w') as f:
                f.write(dockerfile_content)
            
            # Generate .dockerignore
            dockerignore_content = self._generate_dockerignore(tech_stack)
            dockerignore_path = project_path / ".dockerignore"
            
            with open(dockerignore_path, 'w') as f:
                f.write(dockerignore_content)
            
            # Build Docker image
            image_name = f"vedops/{project_path.name.lower()}"
            build_result = self._build_docker_image(project_path, image_name)
            
            # Generate docker-compose.yml
            compose_content = self._generate_docker_compose(image_name, build_plan)
            compose_path = project_path / "docker-compose.yml"
            
            with open(compose_path, 'w') as f:
                f.write(compose_content)
            
            # Generate Kubernetes manifests
            k8s_manifests = self._generate_kubernetes_manifests(image_name, build_plan)
            
            # Save Kubernetes manifests
            k8s_dir = project_path / "k8s"
            k8s_dir.mkdir(exist_ok=True)
            
            for filename, content in k8s_manifests.items():
                with open(k8s_dir / filename, 'w') as f:
                    f.write(content)
            
            # Test container
            test_result = self._test_container(image_name)
            
            self.results = {
                "dockerfile_path": str(dockerfile_path),
                "image_name": image_name,
                "image_id": build_result.get("image_id"),
                "build_logs": build_result.get("logs", []),
                "image_size": build_result.get("size", 0),
                "compose_file": str(compose_path),
                "k8s_manifests": list(k8s_manifests.keys()),
                "test_result": test_result,
                "build_summary": self._generate_build_summary()
            }
            
            self.end_execution(True)
            return self.results
            
        except Exception as e:
            self.add_error(f"Build failed: {str(e)}")
            self.end_execution(False)
            raise
    
    def _generate_dockerfile(self, build_plan: Dict[str, Any], tech_stack: Dict[str, Any]) -> str:
        """Generate optimized Dockerfile"""
        base_image = build_plan["base_image"]
        build_steps = build_plan["build_steps"]
        ports = build_plan.get("ports", [])
        
        dockerfile_lines = [
            f"# Multi-stage Dockerfile generated by VedOps Agni Agent",
            f"# Base image: {base_image}",
            "",
            "# Build stage",
            f"FROM {base_image} AS builder",
            "",
            "# Set working directory",
            "WORKDIR /app",
            "",
            "# Install system dependencies",
            self._get_system_dependencies(tech_stack),
            "",
            "# Copy and install dependencies first (for better caching)",
        ]
        
        # Add build steps
        for step in build_steps:
            dockerfile_lines.append(step)
        
        dockerfile_lines.extend([
            "",
            "# Production stage", 
            f"FROM {base_image} AS production",
            "",
            "# Create non-root user",
            "RUN groupadd -r appuser && useradd -r -g appuser appuser",
            "",
            "# Set working directory",
            "WORKDIR /app",
            "",
            "# Copy built application from builder stage",
            "COPY --from=builder --chown=appuser:appuser /app /app",
            "",
            "# Switch to non-root user",
            "USER appuser",
            ""
        ])
        
        # Add port exposure
        for port in ports:
            dockerfile_lines.append(f"EXPOSE {port}")
        
        # Add health check
        health_check = build_plan.get("health_check")
        if health_check:
            dockerfile_lines.extend([
                "",
                f"HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\",
                f"  CMD {health_check}"
            ])
        
        dockerfile_lines.extend([
            "",
            "# Default command",
            build_steps[-1] if build_steps else 'CMD ["echo", "No command specified"]'
        ])
        
        return "\n".join(dockerfile_lines)
    
    def _get_system_dependencies(self, tech_stack: Dict[str, Any]) -> str:
        """Get system dependencies based on tech stack"""
        primary_lang = tech_stack.get("primary_language")
        
        if primary_lang == "Python":
            return "RUN apt-get update && apt-get install -y --no-install-recommends curl && rm -rf /var/lib/apt/lists/*"
        elif primary_lang in ["JavaScript", "TypeScript"]:
            return "RUN apk add --no-cache curl"
        elif primary_lang == "Java":
            return "RUN apt-get update && apt-get install -y --no-install-recommends curl && rm -rf /var/lib/apt/lists/*"
        else:
            return "RUN apt-get update && apt-get install -y --no-install-recommends curl && rm -rf /var/lib/apt/lists/*"
    
    def _generate_dockerignore(self, tech_stack: Dict[str, Any]) -> str:
        """Generate .dockerignore file"""
        common_ignores = [
            "# VedOps generated .dockerignore",
            ".git",
            ".gitignore", 
            "README.md",
            "Dockerfile*",
            "docker-compose*",
            ".dockerignore",
            "node_modules",
            "npm-debug.log*",
            "yarn-debug.log*",
            "yarn-error.log*",
            ".env",
            ".env.local",
            ".env.*.local",
            "coverage",
            ".nyc_output",
            ".cache",
            ".parcel-cache",
            ".next",
            "out",
            "build",
            "dist",
            "*.log",
            "logs",
            "*.pid",
            "*.seed",
            "*.pid.lock",
            ".DS_Store",
            "Thumbs.db"
        ]
        
        primary_lang = tech_stack.get("primary_language")
        
        if primary_lang == "Python":
            common_ignores.extend([
                "__pycache__",
                "*.py[cod]",
                "*$py.class",
                "*.so",
                ".Python",
                "env",
                "venv",
                ".venv",
                "pip-log.txt",
                "pip-delete-this-directory.txt",
                ".pytest_cache",
                ".coverage",
                "htmlcov",
                ".tox"
            ])
        
        return "\n".join(common_ignores)
    
    def _build_docker_image(self, project_path: Path, image_name: str) -> Dict[str, Any]:
        """Build Docker image"""
        build_logs: List[str] = []
        # Execute docker build
        build_proc = self._run_docker_cmd(["build", "-t", image_name, "."], cwd=project_path)
        if build_proc.stdout:
            for line in build_proc.stdout.splitlines():
                if line.strip():
                    build_logs.append(line.strip())
        # Retrieve image ID
        inspect_id = self._run_docker_cmd(["images", "--no-trunc", "-q", image_name])
        image_id = inspect_id.stdout.strip().splitlines()[0] if inspect_id.stdout.strip() else None
        # Retrieve image size
        size_proc = self._run_docker_cmd(["image", "inspect", "-f", "{{.Size}}", image_name])
        try:
            size_val = int(size_proc.stdout.strip())
        except Exception:
            size_val = 0
        return {
            "image_id": image_id,
            "size": size_val,
            "logs": build_logs,
            "tags": [f"{image_name}:latest"],
        }
    
    def _generate_docker_compose(self, image_name: str, build_plan: Dict[str, Any]) -> str:
        """Generate docker-compose.yml"""
        ports = build_plan.get("ports", [])
        volumes = build_plan.get("volumes", [])
        env_vars = build_plan.get("environment_variables", [])
        
        compose_data = {
            "version": "3.8",
            "services": {
                "app": {
                    "build": ".",
                    "image": image_name,
                    "container_name": f"{image_name.split('/')[-1]}_app",
                    "restart": "unless-stopped",
                    "ports": [f"{port}:{port}" for port in ports],
                    "environment": env_vars,
                    "volumes": volumes,
                    "networks": ["vedops-network"]
                }
            },
            "networks": {
                "vedops-network": {
                    "driver": "bridge"
                }
            }
        }
        
        # Add health check if available
        health_check = build_plan.get("health_check")
        if health_check:
            compose_data["services"]["app"]["healthcheck"] = {
                "test": health_check.split(" ", 1)[1] if " " in health_check else health_check,
                "interval": "30s",
                "timeout": "10s",
                "retries": 3,
                "start_period": "40s"
            }
        
        return yaml.dump(compose_data, default_flow_style=False, sort_keys=False)
    
    def _generate_kubernetes_manifests(self, image_name: str, build_plan: Dict[str, Any]) -> Dict[str, str]:
        """Generate Kubernetes manifests"""
        app_name = image_name.split('/')[-1]
        ports = build_plan.get("ports", [8080])
        primary_port = ports[0] if ports else 8080
        
        # Deployment manifest
        deployment = {
            "apiVersion": "apps/v1",
            "kind": "Deployment", 
            "metadata": {
                "name": f"{app_name}-deployment",
                "labels": {"app": app_name}
            },
            "spec": {
                "replicas": 3,
                "selector": {"matchLabels": {"app": app_name}},
                "template": {
                    "metadata": {"labels": {"app": app_name}},
                    "spec": {
                        "containers": [{
                            "name": app_name,
                            "image": image_name,
                            "ports": [{"containerPort": port} for port in ports],
                            "resources": {
                                "requests": {"memory": "128Mi", "cpu": "100m"},
                                "limits": {"memory": "512Mi", "cpu": "500m"}
                            },
                            "livenessProbe": {
                                "httpGet": {"path": "/health", "port": primary_port},
                                "initialDelaySeconds": 30,
                                "periodSeconds": 10
                            },
                            "readinessProbe": {
                                "httpGet": {"path": "/health", "port": primary_port},
                                "initialDelaySeconds": 5,
                                "periodSeconds": 5
                            }
                        }]
                    }
                }
            }
        }
        
        # Service manifest
        service = {
            "apiVersion": "v1",
            "kind": "Service",
            "metadata": {
                "name": f"{app_name}-service",
                "labels": {"app": app_name}
            },
            "spec": {
                "selector": {"app": app_name},
                "ports": [{"port": 80, "targetPort": primary_port, "protocol": "TCP"}],
                "type": "ClusterIP"
            }
        }
        
        # Ingress manifest
        ingress = {
            "apiVersion": "networking.k8s.io/v1",
            "kind": "Ingress",
            "metadata": {
                "name": f"{app_name}-ingress",
                "annotations": {
                    "nginx.ingress.kubernetes.io/rewrite-target": "/",
                    "cert-manager.io/cluster-issuer": "letsencrypt-prod"
                }
            },
            "spec": {
                "tls": [{
                    "hosts": [f"{app_name}.example.com"],
                    "secretName": f"{app_name}-tls"
                }],
                "rules": [{
                    "host": f"{app_name}.example.com",
                    "http": {
                        "paths": [{
                            "path": "/",
                            "pathType": "Prefix",
                            "backend": {
                                "service": {
                                    "name": f"{app_name}-service",
                                    "port": {"number": 80}
                                }
                            }
                        }]
                    }
                }]
            }
        }
        
        # HPA manifest
        hpa = {
            "apiVersion": "autoscaling/v2",
            "kind": "HorizontalPodAutoscaler",
            "metadata": {"name": f"{app_name}-hpa"},
            "spec": {
                "scaleTargetRef": {
                    "apiVersion": "apps/v1",
                    "kind": "Deployment",
                    "name": f"{app_name}-deployment"
                },
                "minReplicas": 2,
                "maxReplicas": 10,
                "metrics": [{
                    "type": "Resource",
                    "resource": {
                        "name": "cpu",
                        "target": {"type": "Utilization", "averageUtilization": 70}
                    }
                }]
            }
        }
        
        return {
            "deployment.yaml": yaml.dump(deployment, default_flow_style=False),
            "service.yaml": yaml.dump(service, default_flow_style=False),
            "ingress.yaml": yaml.dump(ingress, default_flow_style=False),
            "hpa.yaml": yaml.dump(hpa, default_flow_style=False)
        }
    
    def _test_container(self, image_name: str) -> Dict[str, Any]:
        """Test the built container"""
        try:
            # Run container detached
            run_proc = self._run_docker_cmd(["run", "-d", image_name])
            container_id = run_proc.stdout.strip()
            # Give it a few seconds to start
            import time as _time
            _time.sleep(5)
            # Check container is running
            ps_proc = self._run_docker_cmd(["ps", "-q", "--no-trunc", "--filter", f"id={container_id}"])
            if not ps_proc.stdout.strip():
                # Fetch last logs anyway
                logs_proc = self._run_docker_cmd(["logs", container_id])
                return {"status": "failed", "reason": "Container not running", "logs": logs_proc.stdout[-1000:]}
            # Get logs
            logs_proc = self._run_docker_cmd(["logs", "--tail", "200", container_id])
            # Stop container
            self._run_docker_cmd(["stop", container_id])
            return {
                "status": "success",
                "container_id": container_id,
                "logs": logs_proc.stdout[:1000],
            }
        except Exception as e:
            return {"status": "failed", "reason": str(e)}
    
    def _generate_build_summary(self) -> str:
        """Generate AI-powered build summary"""
        try:
            summary_prompt = f"""
            Analyze this Docker build and provide a summary:
            
            Image: {self.results.get('image_name')}
            Size: {self.results.get('image_size', 0) / (1024*1024):.1f} MB
            Build Status: {'Success' if self.results.get('image_id') else 'Failed'}
            Test Status: {self.results.get('test_result', {}).get('status', 'Unknown')}
            
            Provide:
            1. Build assessment
            2. Image optimization recommendations
            3. Security considerations
            4. Deployment readiness
            """
            
            response = self.llm_client.invoke(summary_prompt)
            return response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            logger.warning(f"Failed to generate AI summary: {e}")
            return "Build completed. Review logs and test results for details."
